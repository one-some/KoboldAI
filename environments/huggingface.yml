name: koboldai
channels:
  - pytorch
  - nvidia
  - conda-forge
  - defaults
dependencies:
  - colorama
  - flask=2.2.3
  - flask-socketio=5.3.2
  - flask-session=0.4.0
  - python-socketio=5.7.2
  - pytorch=2.0.*
  - python=3.8.*
  - pytorch-cuda=11.8
  - eventlet=0.33.3
  - dnspython=2.2.1
  - markdown
  - bleach=4.1.0
  - pip
  - git=2.35.1
  - sentencepiece
  - protobuf
  - marshmallow>=3.13
  - apispec-webframeworks
  - loguru
  - termcolor
  - Pillow
  - psutil
  - pip:
    - flask-cloudflared==0.0.10
    - flask-ngrok
    - flask-cors
    - lupa==1.10
    - transformers==4.31.0
    - huggingface_hub==0.15.1
    - safetensors==0.3.1
    - accelerate==0.20.3
    - git+https://github.com/VE-FORBRYDERNE/mkultra
    - flask-session
    - ansi2html
    - flask_compress
    - ijson
    - bitsandbytes==0.40.0.post4; sys_platform == 'linux'
    - https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.40.0.post4-py3-none-win_amd64.whl; sys_platform == 'win32'
    - ftfy
    - pydub
    - diffusers
    - git+https://github.com/0cc4m/hf_bleeding_edge/
    - https://github.com/0cc4m/GPTQ-for-LLaMa/releases/download/0.0.6/gptq_koboldai-0.0.6-cp38-cp38-linux_x86_64.whl; sys_platform == 'linux'
    - https://github.com/0cc4m/GPTQ-for-LLaMa/releases/download/0.0.6/gptq_koboldai-0.0.6-cp38-cp38-win_amd64.whl; sys_platform == 'win32'
    - einops
    - peft==0.3.0
    - scipy
    - --find-links=https://0cc4m.github.io/exllama/exllama-whl-links.html
    - exllama==0.0.6
